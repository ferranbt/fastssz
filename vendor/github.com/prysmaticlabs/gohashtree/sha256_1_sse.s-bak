/*
MIT License

Copyright (c) 2021 Prysmatic Labs

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
*/
#define MSGSCHEDULE0(index) \
	MOVL	(index*4)(SI), AX; \
	BSWAPL	AX; \
	MOVL	AX, (index*4)(BP)

// Wt = SIGMA1(Wt-2) + Wt-7 + SIGMA0(Wt-15) + Wt-16; for 16 <= t <= 63
//   SIGMA0(x) = ROTR(7,x) XOR ROTR(18,x) XOR SHR(3,x)
//   SIGMA1(x) = ROTR(17,x) XOR ROTR(19,x) XOR SHR(10,x)
#define MSGSCHEDULE1(index) \
	MOVL	((index-2)*4)(BP), AX; \
	MOVL	AX, DI; \
	RORL	$17, AX; \
	MOVL	DI, DX; \
	RORL	$19, DI; \
	SHRL	$10, DX; \
	MOVL	((index-15)*4)(BP), BX; \
	XORL	DI, AX; \
	MOVL	BX, DI; \
	XORL	DX, AX; \
	RORL	$7, BX; \
	MOVL	DI, DX; \
	SHRL	$3, DX; \
	RORL	$18, DI; \
	ADDL	((index-7)*4)(BP), AX; \
	XORL	DI, BX; \
	XORL	DX, BX; \
	ADDL	((index-16)*4)(BP), BX; \
	ADDL	BX, AX; \
	MOVL	AX, ((index)*4)(BP)

// Calculate T1 and T2, then e = d + T1 and a = T1 + T2.  Wt+Kt is passed in AX.
// The values for e and a are stored in d and h, ready for rotation.
#define SHA256ROUND(a, b, c, d, e, f, g, h) \
	MOVL	e, BX; \
	RORL	$14, BX; \
	MOVL	a, DX; \
	RORL	$9, DX; \
	XORL	e, BX; \
	MOVL	f, DI; \
	RORL	$5, BX; \
	XORL	a, DX; \
	XORL	g, DI; \
	XORL	e, BX; \
	ANDL	e, DI; \
	RORL	$11, DX; \
	XORL	a, DX; \
	RORL	$6, BX; \
	XORL	g, DI; \
	RORL	$2, DX; \
	ADDL	BX, DI; \
	ADDL	AX, DI; \
	MOVL	a, BX; \
	ADDL	DI, h; \
	MOVL	a, DI; \
	ORL	c, BX; \
	ADDL	h, d; \
	ANDL	c, DI; \
	ANDL	b, BX; \
	ADDL	DX, h; \
	ORL	DI, BX; \
	ADDL	BX, h	

#define SHA256ROUND0(index, const, a, b, c, d, e, f, g, h) \
	MSGSCHEDULE0(index); \
	ADDL	$const, AX; \
	SHA256ROUND(a, b, c, d, e, f, g, h)

#define SHA256ROUND1(index, const, a, b, c, d, e, f, g, h) \
	MSGSCHEDULE1(index); \
	ADDL	$const, AX; \
	SHA256ROUND(a, b, c, d, e, f, g, h)

#define PADDSHA256ROUND(const, a, b, c, d, e, f, g, h) \
	MOVL	e, BX; \
	RORL	$14, BX; \
	MOVL	a, DX; \
	RORL	$9, DX; \
	XORL	e, BX; \
	MOVL	f, DI; \
	RORL	$5, BX; \
	XORL	a, DX; \
	XORL	g, DI; \
	XORL	e, BX; \
	ANDL	e, DI; \
	RORL	$11, DX; \
	XORL	a, DX; \
	RORL	$6, BX; \
	XORL	g, DI; \
	RORL	$2, DX; \
	ADDL	BX, DI; \
	ADDL	$const, DI; \
	MOVL	a, BX; \
	ADDL	DI, h; \
	MOVL	a, DI; \
	ORL	c, BX; \
	ADDL	h, d; \
	ANDL	c, DI; \
	ANDL	b, BX; \
	ADDL	DX, h; \
	ORL	DI, BX; \
	ADDL	BX, h	

TEXT Â·sha256_1_sse(SB), 0, $296-36

	MOVQ digests+0(FP), CX // digests *[][32]byte
	MOVQ p_base+8(FP), SI  // p [][32]byte
	MOVL count+32(FP), DX  // count uint32
	SHLQ $6, DX

	LEAQ (SI)(DX*1), DI
	MOVQ DI, 256(SP)
	CMPQ SI, DI
	JEQ  end

	MOVQ SP, BP

loop:
	MOVL $0x6A09E667, R8  // a = H0
	MOVL $0xBB67AE85, R9  // b = H1
	MOVL $0x3C6EF372, R10 // c = H2
	MOVL $0xA54FF53A, R11 // d = H3
	MOVL $0x510E527F, R12 // e = H4
	MOVL $0x9B05688C, R13 // f = H5
	MOVL $0x1F83D9AB, R14 // g = H6
	MOVL $0x5BE0CD19, R15 // h = H7


	SHA256ROUND0(0, 0x428a2f98, R8, R9, R10, R11, R12, R13, R14, R15)
	SHA256ROUND0(1, 0x71374491, R15, R8, R9, R10, R11, R12, R13, R14)
	SHA256ROUND0(2, 0xb5c0fbcf, R14, R15, R8, R9, R10, R11, R12, R13)
	SHA256ROUND0(3, 0xe9b5dba5, R13, R14, R15, R8, R9, R10, R11, R12)
	SHA256ROUND0(4, 0x3956c25b, R12, R13, R14, R15, R8, R9, R10, R11)
	SHA256ROUND0(5, 0x59f111f1, R11, R12, R13, R14, R15, R8, R9, R10)
	SHA256ROUND0(6, 0x923f82a4, R10, R11, R12, R13, R14, R15, R8, R9)
	SHA256ROUND0(7, 0xab1c5ed5, R9, R10, R11, R12, R13, R14, R15, R8)
	SHA256ROUND0(8, 0xd807aa98, R8, R9, R10, R11, R12, R13, R14, R15)
	SHA256ROUND0(9, 0x12835b01, R15, R8, R9, R10, R11, R12, R13, R14)
	SHA256ROUND0(10, 0x243185be, R14, R15, R8, R9, R10, R11, R12, R13)
	SHA256ROUND0(11, 0x550c7dc3, R13, R14, R15, R8, R9, R10, R11, R12)
	SHA256ROUND0(12, 0x72be5d74, R12, R13, R14, R15, R8, R9, R10, R11)
	SHA256ROUND0(13, 0x80deb1fe, R11, R12, R13, R14, R15, R8, R9, R10)
	SHA256ROUND0(14, 0x9bdc06a7, R10, R11, R12, R13, R14, R15, R8, R9)
	SHA256ROUND0(15, 0xc19bf174, R9, R10, R11, R12, R13, R14, R15, R8)

	SHA256ROUND1(16, 0xe49b69c1, R8, R9, R10, R11, R12, R13, R14, R15)
	SHA256ROUND1(17, 0xefbe4786, R15, R8, R9, R10, R11, R12, R13, R14)
	SHA256ROUND1(18, 0x0fc19dc6, R14, R15, R8, R9, R10, R11, R12, R13)
	SHA256ROUND1(19, 0x240ca1cc, R13, R14, R15, R8, R9, R10, R11, R12)
	SHA256ROUND1(20, 0x2de92c6f, R12, R13, R14, R15, R8, R9, R10, R11)
	SHA256ROUND1(21, 0x4a7484aa, R11, R12, R13, R14, R15, R8, R9, R10)
	SHA256ROUND1(22, 0x5cb0a9dc, R10, R11, R12, R13, R14, R15, R8, R9)
	SHA256ROUND1(23, 0x76f988da, R9, R10, R11, R12, R13, R14, R15, R8)
	SHA256ROUND1(24, 0x983e5152, R8, R9, R10, R11, R12, R13, R14, R15)
	SHA256ROUND1(25, 0xa831c66d, R15, R8, R9, R10, R11, R12, R13, R14)
	SHA256ROUND1(26, 0xb00327c8, R14, R15, R8, R9, R10, R11, R12, R13)
	SHA256ROUND1(27, 0xbf597fc7, R13, R14, R15, R8, R9, R10, R11, R12)
	SHA256ROUND1(28, 0xc6e00bf3, R12, R13, R14, R15, R8, R9, R10, R11)
	SHA256ROUND1(29, 0xd5a79147, R11, R12, R13, R14, R15, R8, R9, R10)
	SHA256ROUND1(30, 0x06ca6351, R10, R11, R12, R13, R14, R15, R8, R9)
	SHA256ROUND1(31, 0x14292967, R9, R10, R11, R12, R13, R14, R15, R8)
	SHA256ROUND1(32, 0x27b70a85, R8, R9, R10, R11, R12, R13, R14, R15)
	SHA256ROUND1(33, 0x2e1b2138, R15, R8, R9, R10, R11, R12, R13, R14)
	SHA256ROUND1(34, 0x4d2c6dfc, R14, R15, R8, R9, R10, R11, R12, R13)
	SHA256ROUND1(35, 0x53380d13, R13, R14, R15, R8, R9, R10, R11, R12)
	SHA256ROUND1(36, 0x650a7354, R12, R13, R14, R15, R8, R9, R10, R11)
	SHA256ROUND1(37, 0x766a0abb, R11, R12, R13, R14, R15, R8, R9, R10)
	SHA256ROUND1(38, 0x81c2c92e, R10, R11, R12, R13, R14, R15, R8, R9)
	SHA256ROUND1(39, 0x92722c85, R9, R10, R11, R12, R13, R14, R15, R8)
	SHA256ROUND1(40, 0xa2bfe8a1, R8, R9, R10, R11, R12, R13, R14, R15)
	SHA256ROUND1(41, 0xa81a664b, R15, R8, R9, R10, R11, R12, R13, R14)
	SHA256ROUND1(42, 0xc24b8b70, R14, R15, R8, R9, R10, R11, R12, R13)
	SHA256ROUND1(43, 0xc76c51a3, R13, R14, R15, R8, R9, R10, R11, R12)
	SHA256ROUND1(44, 0xd192e819, R12, R13, R14, R15, R8, R9, R10, R11)
	SHA256ROUND1(45, 0xd6990624, R11, R12, R13, R14, R15, R8, R9, R10)
	SHA256ROUND1(46, 0xf40e3585, R10, R11, R12, R13, R14, R15, R8, R9)
	SHA256ROUND1(47, 0x106aa070, R9, R10, R11, R12, R13, R14, R15, R8)
	SHA256ROUND1(48, 0x19a4c116, R8, R9, R10, R11, R12, R13, R14, R15)
	SHA256ROUND1(49, 0x1e376c08, R15, R8, R9, R10, R11, R12, R13, R14)
	SHA256ROUND1(50, 0x2748774c, R14, R15, R8, R9, R10, R11, R12, R13)
	SHA256ROUND1(51, 0x34b0bcb5, R13, R14, R15, R8, R9, R10, R11, R12)
	SHA256ROUND1(52, 0x391c0cb3, R12, R13, R14, R15, R8, R9, R10, R11)
	SHA256ROUND1(53, 0x4ed8aa4a, R11, R12, R13, R14, R15, R8, R9, R10)
	SHA256ROUND1(54, 0x5b9cca4f, R10, R11, R12, R13, R14, R15, R8, R9)
	SHA256ROUND1(55, 0x682e6ff3, R9, R10, R11, R12, R13, R14, R15, R8)
	SHA256ROUND1(56, 0x748f82ee, R8, R9, R10, R11, R12, R13, R14, R15)
	SHA256ROUND1(57, 0x78a5636f, R15, R8, R9, R10, R11, R12, R13, R14)
	SHA256ROUND1(58, 0x84c87814, R14, R15, R8, R9, R10, R11, R12, R13)
	SHA256ROUND1(59, 0x8cc70208, R13, R14, R15, R8, R9, R10, R11, R12)
	SHA256ROUND1(60, 0x90befffa, R12, R13, R14, R15, R8, R9, R10, R11)
	SHA256ROUND1(61, 0xa4506ceb, R11, R12, R13, R14, R15, R8, R9, R10)
	SHA256ROUND1(62, 0xbef9a3f7, R10, R11, R12, R13, R14, R15, R8, R9)
	SHA256ROUND1(63, 0xc67178f2, R9, R10, R11, R12, R13, R14, R15, R8)

	// Add initial digest and save it
	ADDL $0x6A09E667, R8  // H0 = a + H0
	MOVL R8, (0*4)(CX)
	ADDL $0xBB67AE85, R9  // H1 = b + H1
	MOVL R9, (1*4)(CX)
	ADDL $0x3C6EF372, R10 // H2 = c + H2
	MOVL R10, (2*4)(CX)
	ADDL $0xA54FF53A, R11 // H3 = d + H3
	MOVL R11, (3*4)(CX)
	ADDL $0x510E527F, R12 // H4 = e + H4
	MOVL R12, (4*4)(CX)
	ADDL $0x9B05688C, R13 // H5 = f + H5
	MOVL R13, (5*4)(CX)
	ADDL $0x1F83D9AB, R14 // H6 = g + H6
	MOVL R14, (6*4)(CX)
	ADDL $0x5BE0CD19, R15 // H7 = h + H7
	MOVL R15, (7*4)(CX)

	// Rounds with padding
	// Rounds 0 - 15
	PADDSHA256ROUND(0xc28a2f98, R8, R9, R10, R11, R12, R13, R14, R15)
	PADDSHA256ROUND(0x71374491, R15, R8, R9, R10, R11, R12, R13, R14)
	PADDSHA256ROUND(0xb5c0fbcf, R14, R15, R8, R9, R10, R11, R12, R13)
	PADDSHA256ROUND(0xe9b5dba5, R13, R14, R15, R8, R9, R10, R11, R12)
	PADDSHA256ROUND(0x3956c25b, R12, R13, R14, R15, R8, R9, R10, R11)
	PADDSHA256ROUND(0x59f111f1, R11, R12, R13, R14, R15, R8, R9, R10)
	PADDSHA256ROUND(0x923f82a4, R10, R11, R12, R13, R14, R15, R8, R9)
	PADDSHA256ROUND(0xab1c5ed5, R9, R10, R11, R12, R13, R14, R15, R8)
	PADDSHA256ROUND(0xd807aa98, R8, R9, R10, R11, R12, R13, R14, R15)
	PADDSHA256ROUND(0x12835b01, R15, R8, R9, R10, R11, R12, R13, R14)
	PADDSHA256ROUND(0x243185be, R14, R15, R8, R9, R10, R11, R12, R13)
	PADDSHA256ROUND(0x550c7dc3, R13, R14, R15, R8, R9, R10, R11, R12)
	PADDSHA256ROUND(0x72be5d74, R12, R13, R14, R15, R8, R9, R10, R11)
	PADDSHA256ROUND(0x80deb1fe, R11, R12, R13, R14, R15, R8, R9, R10)
	PADDSHA256ROUND(0x9bdc06a7, R10, R11, R12, R13, R14, R15, R8, R9)
	PADDSHA256ROUND(0xc19bf374, R9, R10, R11, R12, R13, R14, R15, R8)

	// Rounds 16 - 31
	PADDSHA256ROUND(0x649b69c1, R8, R9, R10, R11, R12, R13, R14, R15)
	PADDSHA256ROUND(0xf0fe4786, R15, R8, R9, R10, R11, R12, R13, R14)
	PADDSHA256ROUND(0x0fe1edc6, R14, R15, R8, R9, R10, R11, R12, R13)
	PADDSHA256ROUND(0x240cf254, R13, R14, R15, R8, R9, R10, R11, R12)
	PADDSHA256ROUND(0x4fe9346f, R12, R13, R14, R15, R8, R9, R10, R11)
	PADDSHA256ROUND(0x6cc984be, R11, R12, R13, R14, R15, R8, R9, R10)
	PADDSHA256ROUND(0x61b9411e, R10, R11, R12, R13, R14, R15, R8, R9)
	PADDSHA256ROUND(0x16f988fa, R9, R10, R11, R12, R13, R14, R15, R8)
	PADDSHA256ROUND(0xf2c65152, R8, R9, R10, R11, R12, R13, R14, R15)
	PADDSHA256ROUND(0xa88e5a6d, R15, R8, R9, R10, R11, R12, R13, R14)
	PADDSHA256ROUND(0xb019fc65, R14, R15, R8, R9, R10, R11, R12, R13)
	PADDSHA256ROUND(0xb9d99ec7, R13, R14, R15, R8, R9, R10, R11, R12)
	PADDSHA256ROUND(0x9a1231c3, R12, R13, R14, R15, R8, R9, R10, R11)
	PADDSHA256ROUND(0xe70eeaa0, R11, R12, R13, R14, R15, R8, R9, R10)
	PADDSHA256ROUND(0xfdb1232b, R10, R11, R12, R13, R14, R15, R8, R9)
	PADDSHA256ROUND(0xc7353eb0, R9, R10, R11, R12, R13, R14, R15, R8)

	// Rounds 32 - 48
	PADDSHA256ROUND(0x3069bad5, R8, R9, R10, R11, R12, R13, R14, R15)
	PADDSHA256ROUND(0xcb976d5f, R15, R8, R9, R10, R11, R12, R13, R14)
	PADDSHA256ROUND(0x5a0f118f, R14, R15, R8, R9, R10, R11, R12, R13)
	PADDSHA256ROUND(0xdc1eeefd, R13, R14, R15, R8, R9, R10, R11, R12)
	PADDSHA256ROUND(0x0a35b689, R12, R13, R14, R15, R8, R9, R10, R11)
	PADDSHA256ROUND(0xde0b7a04, R11, R12, R13, R14, R15, R8, R9, R10)
	PADDSHA256ROUND(0x58f4ca9d, R10, R11, R12, R13, R14, R15, R8, R9)
	PADDSHA256ROUND(0xe15d5b16, R9, R10, R11, R12, R13, R14, R15, R8)
	PADDSHA256ROUND(0x007f3e86, R8, R9, R10, R11, R12, R13, R14, R15)
	PADDSHA256ROUND(0x37088980, R15, R8, R9, R10, R11, R12, R13, R14)
	PADDSHA256ROUND(0xa507ea32, R14, R15, R8, R9, R10, R11, R12, R13)
	PADDSHA256ROUND(0x6fab9537, R13, R14, R15, R8, R9, R10, R11, R12)
	PADDSHA256ROUND(0x17406110, R12, R13, R14, R15, R8, R9, R10, R11)
	PADDSHA256ROUND(0x0d8cd6f1, R11, R12, R13, R14, R15, R8, R9, R10)
	PADDSHA256ROUND(0xcdaa3b6d, R10, R11, R12, R13, R14, R15, R8, R9)
	PADDSHA256ROUND(0xc0bbbe37, R9, R10, R11, R12, R13, R14, R15, R8)

	// Rounds 49 - 64
	PADDSHA256ROUND(0x83613bda, R8, R9, R10, R11, R12, R13, R14, R15)
	PADDSHA256ROUND(0xdb48a363, R15, R8, R9, R10, R11, R12, R13, R14)
	PADDSHA256ROUND(0x0b02e931, R14, R15, R8, R9, R10, R11, R12, R13)
	PADDSHA256ROUND(0x6fd15ca7, R13, R14, R15, R8, R9, R10, R11, R12)
	PADDSHA256ROUND(0x521afaca, R12, R13, R14, R15, R8, R9, R10, R11)
	PADDSHA256ROUND(0x31338431, R11, R12, R13, R14, R15, R8, R9, R10)
	PADDSHA256ROUND(0x6ed41a95, R10, R11, R12, R13, R14, R15, R8, R9)
	PADDSHA256ROUND(0x6d437890, R9, R10, R11, R12, R13, R14, R15, R8)
	PADDSHA256ROUND(0xc39c91f2, R8, R9, R10, R11, R12, R13, R14, R15)
	PADDSHA256ROUND(0x9eccabbd, R15, R8, R9, R10, R11, R12, R13, R14)
	PADDSHA256ROUND(0xb5c9a0e6, R14, R15, R8, R9, R10, R11, R12, R13)
	PADDSHA256ROUND(0x532fb63c, R13, R14, R15, R8, R9, R10, R11, R12)
	PADDSHA256ROUND(0xd2c741c6, R12, R13, R14, R15, R8, R9, R10, R11)
	PADDSHA256ROUND(0x07237ea3, R11, R12, R13, R14, R15, R8, R9, R10)
	PADDSHA256ROUND(0xa4954b68, R10, R11, R12, R13, R14, R15, R8, R9)
	PADDSHA256ROUND(0x4c191d76, R9, R10, R11, R12, R13, R14, R15, R8)

	// Add previous digest and save it
	ADDL (0*4)(CX), R8  // H0 = a + H0
	BSWAPL R8
	MOVL R8, (0*4)(CX)
	ADDL (1*4)(CX), R9  // H1 = b + H1
	BSWAPL R9
	MOVL R9, (1*4)(CX)
	ADDL (2*4)(CX), R10 // H2 = c + H2
	BSWAPL R10
	MOVL R10, (2*4)(CX)
	ADDL (3*4)(CX), R11 // H3 = d + H3
	BSWAPL R11
	MOVL R11, (3*4)(CX)
	ADDL (4*4)(CX), R12 // H4 = e + H4
	BSWAPL R12
	MOVL R12, (4*4)(CX)
	ADDL (5*4)(CX), R13 // H5 = f + H5
	BSWAPL R13
	MOVL R13, (5*4)(CX)
	ADDL (6*4)(CX), R14 // H6 = g + H6
	BSWAPL R14
	MOVL R14, (6*4)(CX)
	ADDL (7*4)(CX), R15 // H7 = h + H7
	BSWAPL R15
	MOVL R15, (7*4)(CX)

	ADDQ $64, SI
	ADDQ $32, CX
	CMPQ SI, 256(SP)
	JB   loop

end:
	RET
